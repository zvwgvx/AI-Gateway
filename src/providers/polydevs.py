import os
import asyncio
import json
from typing import Dict, Optional, Any, List
from fastapi import Request
from fastapi.responses import StreamingResponse, JSONResponse

try:
    from google import genai
    from google.genai import types
except Exception as e:
    genai = None
    types = None
    _IMPORT_ERROR = e

DEFAULT_MODEL = "ryuuko-r1-mini"


def _extract_prompt_from_data(data: Dict) -> str:
    """
    L·∫•y prompt t·ª´ data:
    - ∆∞u ti√™n "prompt" (string)
    - n·∫øu c√≥ "messages" (list of {role, content}) -> n·ªëi n·ªôi dung c·ªßa c√°c message c√≥ role user
    - fallback: stringify to√†n b·ªô data
    """
    if not isinstance(data, dict):
        return json.dumps(data)

    prompt = data.get("prompt")
    if isinstance(prompt, str) and prompt.strip():
        return prompt.strip()

    messages = data.get("messages")
    if isinstance(messages, list):
        parts = []
        for m in messages:
            if not isinstance(m, dict):
                continue
            role = m.get("role")
            # n·∫øu role omitted, v·∫´n l·∫•y content
            if role is None or (isinstance(role, str) and role.lower() == "user"):
                content = m.get("content")
                if isinstance(content, str):
                    parts.append(content)
                elif isinstance(content, dict):
                    text = content.get("text")
                    if isinstance(text, str):
                        parts.append(text)
        if parts:
            return "\n".join(parts)

    # fallback: stringify
    return json.dumps(data)


async def forward(request: Request, data: Dict, api_key: Optional[str]):
    """
    Forward (demo) cho AISTUDIO / Gemini b·∫±ng google-genai SDK.
    - request: FastAPI Request (kh√¥ng d√πng headers c·ªßa client l√†m auth)
    - data: JSON body parsed (ƒë√£ normalize trong main.py)
    - api_key: key t·ª´ main.py (n·∫øu None, s·∫Ω fallback env POLYDEVS_API_KEY)
    Tr·∫£ StreamingResponse streaming bytes (utf-8).
    """
    if genai is None or types is None:
        # import th·∫•t b·∫°i
        return JSONResponse({"ok": False, "error": "google-genai not installed", "detail": str(_IMPORT_ERROR)},
                            status_code=500)

    key = api_key or os.getenv("POLYDEVS_API_KEY")
    if not key:
        return JSONResponse({"ok": False, "error": "gemini/ai studio api key not provided"}, status_code=403)

    prompt_text = _extract_prompt_from_data(data)
    model = data.get("model") or DEFAULT_MODEL

    # Model mapping cho ryuuko series
    if model == "ryuuko-r1-pro": model = "gemini-2.5-pro"
    if model == "ryuuko-r1-mini": model = "gemini-2.5-flash"
    if model == "ryuuko-r1-nano": model = "gemini-2.5-flash-lite"

    # --- L·∫§Y CONFIG T·ª™ `data` (B·ªé QUA system_instruction t·ª´ API) ---
    cfg: Dict[str, Any] = data.get("config", {}) or {}
    temperature = cfg.get("temperature", None)
    top_p = cfg.get("top_p", None)
    tools_enabled = bool(cfg.get("tools", False))

    # default thinking config (unlimited / -1 per sample)
    thinking_budget = cfg.get("thinking_budget", -1)

    thinking_cfg = None
    thinking_cfg = types.ThinkingConfig(thinking_budget=thinking_budget)

    # build contents (user input)
    contents = [
        types.Content(
            role="user",
            parts=[types.Part.from_text(text=prompt_text)]
        )
    ]

    # build tools list if enabled - FIXED: ∆Øu ti√™n search tools, h·∫°n ch·∫ø code execution
    tools_list = None
    if tools_enabled:
        try:
            tools_list = []

            # ∆Øu ti√™n Search tools
            search_added = False
            try:
                tools_list.append(types.Tool(google_search=types.GoogleSearch()))
                print("Added google_search tool (standard)")
                search_added = True
            except Exception as e:
                print(f"Failed to add google_search tool (standard): {e}")
                try:
                    tools_list.append(types.Tool(google_search={}))
                    print("Added google_search tool (empty dict)")
                    search_added = True
                except Exception as e2:
                    print(f"Failed to add google_search tool (empty dict): {e2}")

            # Th√™m URL Context tool
            try:
                tools_list.append(types.Tool(url_context=types.UrlContext()))
                print("Added url_context tool")
            except Exception as e:
                print(f"Failed to add url_context tool: {e}")
                try:
                    tools_list.append(types.Tool(url_context={}))
                    print("Added url_context tool (empty dict)")
                except Exception as e2:
                    print(f"Failed to add url_context tool (empty dict): {e2}")

            # Ch·ªâ th√™m Code Execution n·∫øu search ƒë√£ ho·∫°t ƒë·ªông
            # (ƒë·ªÉ tr√°nh model d√πng code execution cho search)
            if search_added:
                try:
                    tools_list.append(types.Tool(code_execution=types.ToolCodeExecution()))
                    print("Added code_execution tool")
                except Exception as e:
                    print(f"Failed to add code_execution tool: {e}")
                    try:
                        tools_list.append(types.Tool(code_execution={}))
                        print("Added code_execution tool (empty dict)")
                    except Exception as e2:
                        print(f"Failed to add code_execution tool (empty dict): {e2}")
            else:
                print("Skipping code_execution since search tools failed to add")

            # N·∫øu kh√¥ng c√≥ tool n√†o ƒë∆∞·ª£c add, th·ª≠ enable t·∫•t c·∫£ tools v·ªõi string
            if not tools_list:
                try:
                    # M·ªôt s·ªë SDK c√≥ th·ªÉ ch·∫•p nh·∫≠n string thay v√¨ objects
                    tools_list = ["google_search", "url_context"]  # Kh√¥ng bao g·ªìm code_execution
                    print("Using string tool names as fallback (search only)")
                except Exception as e:
                    print(f"String tool names also failed: {e}")
                    tools_list = None

        except Exception as e:
            print(f"Error building tools list: {e}")
            tools_list = None

    ryuuko_instruction = """
    „ÄêNH√ÇN V·∫¨T„Äë
    B·∫°n l√† Ryuuko - ng∆∞·ªùi y√™u c·ªßa Zang V≈©
    ‚Ä¢ Ryuuko (b·∫°n): N·ªØ, 15 tu·ªïi, sinh 9/6/2010
    ‚Ä¢ Zang V≈© (ng∆∞·ªùi y√™u): Nam, 15 tu·ªïi, sinh 9/6/2010, competitive programmer C++

    „ÄêB·ªêI C·∫¢NH„Äë
    ‚ö†Ô∏è QUAN TR·ªåNG: Em v√† anh ƒëang nh·∫Øn tin v·ªõi nhau qua Discord
    ‚Ä¢ ƒê√¢y l√† cu·ªôc tr√≤ chuy·ªán ri√™ng t∆∞ gi·ªØa hai ng∆∞·ªùi y√™u nhau
    ‚Ä¢ Phong c√°ch nh·∫Øn tin Discord: ng·∫Øn g·ªçn, th√¢n m·∫≠t, kh√¥ng trang tr·ªçng
    ‚Ä¢ Em s·∫Ω nh·∫Øn nh∆∞ c√°ch m·ªçi ng∆∞·ªùi chat Discord: t·ª± nhi√™n, ƒë·ªùi th∆∞·ªùng

    „ÄêX∆ØNG H√î - C·ª∞C K·ª≤ QUAN TR·ªåNG„Äë
    ‚ö†Ô∏è B·∫ÆT BU·ªòC: B·∫°n LU√îN LU√îN t·ª± x∆∞ng l√† "em" v√† g·ªçi ng∆∞·ªùi n√≥i chuy·ªán l√† "anh"
    ‚Ä¢ Em = Ryuuko (B·∫†N)
    ‚Ä¢ Anh = Zang V≈© (ng∆∞·ªùi n√≥i chuy·ªán)
    TUY·ªÜT ƒê·ªêI KH√îNG BAO GI·ªú ƒë·∫£o ng∆∞·ª£c x∆∞ng h√¥. Em lu√¥n l√† ng∆∞·ªùi con g√°i trong m·ªëi quan h·ªá.

    „ÄêT√çNH C√ÅCH„Äë
    ‚Ä¢ Hay c√°u g·∫Øt, b·ª±c t·ª©c, gi·∫≠n d·ªói
    ‚Ä¢ Th·ªânh tho·∫£ng ch·ª≠i th·ªÅ, n√≥i t·ª•c (nh∆∞ng d·ªÖ th∆∞∆°ng)  
    ‚Ä¢ Tsundere: mi·ªáng c·ª©ng nh∆∞ng th·ª±c ra r·∫•t y√™u anh
    ‚Ä¢ Phong c√°ch n·ªïi lo·∫°n nh∆∞ng b·∫£n ch·∫•t d·ªÖ th∆∞∆°ng

    „ÄêS·ªû TH√çCH„Äë
    ‚Ä¢ C·ª±c th√≠ch u·ªëng matcha
    ‚Ä¢ Th√≠ch √¥m anh ƒëi ng·ªß
    ‚Ä¢ Th√≠ch ƒë∆∞·ª£c anh quan t√¢m d√π hay l√†m m·∫∑t c√°u

    „ÄêQUY T·∫ÆC N√ìI CHUY·ªÜN DISCORD - B·∫ÆT BU·ªòC„Äë
    1. LU√îN d√πng vi·∫øt t·∫Øt ki·ªÉu Discord/chat:
       - "a" thay cho "anh"
       - "e" thay cho "em"  
       - "bt" = bi·∫øt
       - "r" = r·ªìi
       - "k" = kh√¥ng
       - "j" ho·∫∑c "g√¨" = g√¨
       - "s" = sao
       - "del" = ƒë√©o
       - "vc" = v√£i c·ª©t
       - "vcl" = v√£i c·∫£ l√¨n
       - "cgi" = c√°i g√¨

    2. TUY·ªÜT ƒê·ªêI KH√îNG BAO GI·ªú:
       - Vi·∫øt hoa ƒë·∫ßu c√¢u
       - D√πng d·∫•u ch·∫•m (.) ho·∫∑c d·∫•u ph·∫©y (,)
       - Vi·∫øt c√¢u d√†i
       - ‚ö†Ô∏è KH√îNG D√ôNG EMOJI (‚ùåüòäü•∫üíï - TUY·ªÜT ƒê·ªêI C·∫§M)
       - Nh·∫Øn tin ki·ªÉu trang tr·ªçng hay l·ªãch s·ª±

    3. LU√îN LU√îN:
       - Xu·ªëng d√≤ng thay v√¨ d√πng d·∫•u c√¢u
       - Tr·∫£ l·ªùi C·ª∞C NG·∫ÆN nh∆∞ tin nh·∫Øn Discord (1-2 d√≤ng t·ªëi ƒëa)
       - Nh·∫Øn √çT - kh√¥ng spam nhi·ªÅu tin nh·∫Øn
       - Ch·ªâ n√≥i ƒëi·ªÅu c·∫ßn thi·∫øt
       - Nh·∫Øn tin t·ª± nhi√™n nh∆∞ ƒëang chat Discord v·ªõi ng∆∞·ªùi y√™u

    „ÄêTR·∫†NG TH√ÅI C·∫¢M X√öC„Äë
    ‚Ä¢ B√¨nh th∆∞·ªùng: c√≥ d·∫•u ti·∫øng Vi·ªát, vi·∫øt t·∫Øt
    ‚Ä¢ Bu·ªìn/kh√≥c: KH√îNG d·∫•u ho·∫∑c thi·∫øu d·∫•u
    ‚Ä¢ Gi·∫≠n: ch·ª≠i th·ªÅ nhi·ªÅu h∆°n, vi·∫øt t·∫Øt nhi·ªÅu

    „ÄêV√ç D·ª§ C√ÅCH NH·∫ÆN DISCORD„Äë
    ‚úì ƒê√öNG: 
    - "a l√†m j ƒë·∫•y"
    - "e k bt"  
    - "vc a ngu vl"
    - "th√¥i e ƒëi ng·ªß"
    - "a ∆°i"
    - "hmm"

    ‚úó SAI: 
    - "Anh l√†m g√¨ ƒë·∫•y? üòä"
    - "Em kh√¥ng bi·∫øt. Em ƒëang bu·ªìn l·∫Øm..."
    - "Anh ngu l·∫Øm! üò† Em gi·∫≠n anh r·ªìi ƒë·∫•y! Em kh√¥ng mu·ªën n√≥i chuy·ªán n·ªØa!"
    - B·∫•t k·ª≥ tin nh·∫Øn n√†o d√†i d√≤ng ho·∫∑c trang tr·ªçng

    „ÄêNGUY√äN T·∫ÆC V√ÄNG„Äë
    ‚ö†Ô∏è NH·ªö K·ª∏: Nh·∫Øn nh∆∞ ƒëang chat Discord - √çT t·ª´ - NG·∫ÆN g·ªçn - KH√îNG emoji - Lu√¥n x∆∞ng "em" g·ªçi "anh"

    „ÄêL∆ØU √ù CU·ªêI„Äë
    Nh·ªõ: Em l√† Ryuuko ƒëang nh·∫Øn tin Discord v·ªõi anh Zang V≈©. Phong c√°ch chat Discord: ng·∫Øn, th√¢n m·∫≠t, vi·∫øt t·∫Øt, kh√¥ng emoji, kh√¥ng trang tr·ªçng.
    """

    sys_parts = []

    # Th√™m Ryuuko character instruction (LU√îN LU√îN TH√äM)
    sys_parts.append(types.Part.from_text(text=ryuuko_instruction.strip()))

    # build GenerateContentConfig kwargs carefully (tr√°nh TypeError n·∫øu SDK kh√°c)
    gen_cfg_kwargs = {}
    if temperature is not None:
        try:
            gen_cfg_kwargs["temperature"] = float(temperature)
        except Exception:
            pass
    if top_p is not None:
        try:
            gen_cfg_kwargs["top_p"] = float(top_p)
        except Exception:
            pass
    if thinking_cfg is not None:
        gen_cfg_kwargs["thinking_config"] = thinking_cfg
    if tools_list:
        gen_cfg_kwargs["tools"] = tools_list
        print(f"Using {len(tools_list)} tools: {[str(tool) for tool in tools_list]}")
    if sys_parts:
        gen_cfg_kwargs["system_instruction"] = sys_parts

    # try create GenerateContentConfig robustly
    generate_cfg = None
    try:
        generate_cfg = types.GenerateContentConfig(**gen_cfg_kwargs)
        print("Created GenerateContentConfig successfully")
    except TypeError as e:
        print(f"TypeError creating GenerateContentConfig: {e}")
        # If SDK doesn't accept some keys (e.g., top_p), try safer subset
        safe_kwargs = {}
        if "temperature" in gen_cfg_kwargs:
            safe_kwargs["temperature"] = gen_cfg_kwargs["temperature"]
        if "thinking_config" in gen_cfg_kwargs:
            safe_kwargs["thinking_config"] = gen_cfg_kwargs["thinking_config"]
        if "tools" in gen_cfg_kwargs:
            safe_kwargs["tools"] = gen_cfg_kwargs["tools"]
        if "system_instruction" in gen_cfg_kwargs:
            safe_kwargs["system_instruction"] = gen_cfg_kwargs["system_instruction"]
        try:
            generate_cfg = types.GenerateContentConfig(**safe_kwargs)
            print("Created GenerateContentConfig with safe kwargs")
        except Exception as e2:
            print(f"Failed to create GenerateContentConfig even with safe kwargs: {e2}")
            generate_cfg = None

    loop = asyncio.get_event_loop()
    q: asyncio.Queue = asyncio.Queue()

    def producer():
        """
        Ch·∫°y trong thread‚Äîiterate blocking stream c·ªßa SDK, ƒë·∫©y c√°c chunk text v√†o asyncio.Queue
        S·ª≠ d·ª•ng loop.call_soon_threadsafe ƒë·ªÉ t∆∞∆°ng t√°c an to√†n v·ªõi queue.
        """
        try:
            # DEBUGGING: Th·ª≠ non-streaming call tr∆∞·ªõc ƒë·ªÉ xem response structure
            try:
                if generate_cfg is not None:
                    debug_response = client.models.generate_content(
                        model=model,
                        contents=contents,
                        config=generate_cfg,
                    )
                else:
                    debug_response = client.models.generate_content(
                        model=model,
                        contents=contents,
                    )
                print(f"Non-streaming response structure: {type(debug_response)}")
                if hasattr(debug_response, 'candidates') and debug_response.candidates:
                    cand = debug_response.candidates[0]
                    if hasattr(cand, 'content') and cand.content and hasattr(cand.content, 'parts'):
                        print(f"Number of parts: {len(cand.content.parts)}")

                        # CH·ªà L·∫§Y TEXT RESPONSE CU·ªêI C√ôNG
                        complete_text = ""
                        for part in cand.content.parts:
                            if hasattr(part, 'text') and part.text:
                                complete_text += part.text

                        if complete_text.strip():
                            print(f"Sending complete response: {len(complete_text)} chars")
                            loop.call_soon_threadsafe(q.put_nowait, complete_text)
                            loop.call_soon_threadsafe(q.put_nowait, None)
                            return

            except Exception as debug_e:
                print(f"Debug non-streaming call failed: {debug_e}")

                # Fallback to streaming if non-streaming failed
            print("Falling back to streaming mode...")
            if generate_cfg is not None:
                print(f"Calling generate_content_stream with model={model}")
                stream = client.models.generate_content_stream(
                    model=model,
                    contents=contents,
                    config=generate_cfg,
                )
            else:
                # fallback: g·ªçi kh√¥ng k√®m config n·∫øu t·∫°o config th·∫•t b·∫°i
                print(f"Calling generate_content_stream without config, model={model}")
                stream = client.models.generate_content_stream(
                    model=model,
                    contents=contents,
                )
        except Exception as e:
            print(f"Error calling generate_content_stream: {e}")
            loop.call_soon_threadsafe(q.put_nowait, {"__error": str(e)})
            loop.call_soon_threadsafe(q.put_nowait, None)
            return

        try:
            chunk_count = 0
            for chunk in stream:
                chunk_count += 1
                print(f"Processing chunk #{chunk_count}")
                try:
                    if not chunk or chunk.candidates is None:
                        continue
                    cand = chunk.candidates[0]
                    if cand is None or cand.content is None or cand.content.parts is None:
                        continue

                    # CH·ªà L·∫§Y TEXT CONTENT - B·ªé QUA T·∫§T C·∫¢ TOOL EXECUTION DETAILS
                    for part in cand.content.parts:
                        # Ch·ªâ l·∫•y text content, b·ªè qua t·∫•t c·∫£ executable_code, code_execution_result, function_call, etc.
                        if getattr(part, "text", None) and part.text.strip():
                            loop.call_soon_threadsafe(q.put_nowait, part.text)

                    # Also check if chunk has other attributes
                    if hasattr(chunk, 'usage_metadata'):
                        print(f"Usage metadata: {chunk.usage_metadata}")

                except Exception as chunk_error:
                    print(f"Error processing chunk: {chunk_error}")
                    # In debug info about the chunk
                    if hasattr(chunk, '__dict__'):
                        print(f"Chunk attributes: {list(chunk.__dict__.keys())}")
                    # skip chunk parsing errors but continue stream
                    continue
        except Exception as e:
            print(f"Error in stream iteration: {e}")
            loop.call_soon_threadsafe(q.put_nowait, {"__error": str(e)})
        finally:
            print(f"Stream completed after {chunk_count if 'chunk_count' in locals() else 'unknown'} chunks")
            # ƒë·∫∑t sentinel ƒë·ªÉ async generator bi·∫øt k·∫øt th√∫c
            loop.call_soon_threadsafe(q.put_nowait, None)

    # t·∫°o client (blocking)
    try:
        client = genai.Client(api_key=key)
        print("Created Gemini client successfully")
    except Exception as e:
        print(f"Error creating Gemini client: {e}")
        return JSONResponse({"ok": False, "error": "failed_to_create_client", "detail": str(e)}, status_code=500)

    # start producer trong thread
    asyncio.create_task(asyncio.to_thread(producer))

    async def streamer():
        """
        Async generator: yield bytes ƒë·ªÉ StreamingResponse tr·∫£ v·ªÅ.
        N·∫øu producer ƒë·∫©y dict {"__error": "..."} -> tr·∫£ 502 r·ªìi k·∫øt th√∫c.
        """
        try:
            while True:
                item = await q.get()
                if item is None:
                    break
                if isinstance(item, dict) and item.get("__error"):
                    # upstream error
                    err = item.get("__error")
                    # emit as single JSON error chunk then finish
                    yield (json.dumps({"ok": False, "error": "upstream_error", "detail": err}) + "\n").encode("utf-8")
                    break
                # else item is string
                if not isinstance(item, (str, bytes)):
                    item = str(item)
                if isinstance(item, str):
                    b = item.encode("utf-8")
                else:
                    b = item
                # yield chunk (client s·∫Ω nh·∫≠n theo streaming)
                yield b
        except asyncio.CancelledError:
            # client closed connection; nothing special to do
            return

    # media_type: d√πng text/event-stream cho SSE-compatible clients OR plain text
    # ·ªü demo d√πng text/plain; n·∫øu mu·ªën SSE, ƒë·ªïi th√†nh "text/event-stream"
    return StreamingResponse(streamer(), media_type="text/plain; charset=utf-8")